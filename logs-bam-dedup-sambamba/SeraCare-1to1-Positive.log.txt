finding positions of the duplicate reads in the file...
  sorted 9184 end pairs
     and 8 single ends (among them 4 unmatched pairs)
  collecting indices of duplicate reads...   done in 12 ms
  found 8881 duplicates
collected list of positions in 0 min 0 sec
removing duplicates...
total time elapsed: 0 min 0 sec

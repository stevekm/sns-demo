finding positions of the duplicate reads in the file...
  sorted 12160 end pairs
     and 19 single ends (among them 15 unmatched pairs)
  collecting indices of duplicate reads...   done in 16 ms
  found 11992 duplicates
collected list of positions in 0 min 0 sec
removing duplicates...
total time elapsed: 0 min 0 sec
